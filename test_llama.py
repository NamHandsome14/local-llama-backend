from ctransformers import AutoModelForCausalLM
import os

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_DIR = os.path.join(BASE_DIR, "models")

print("ğŸ”„ Äang load model LLaMA 2, vui lÃ²ng chá»...")

llm = AutoModelForCausalLM.from_pretrained(
    MODEL_DIR,
    model_file="llama-2-7b-chat.Q4_K_M.gguf",
    model_type="llama",
    context_length=2048,
    max_new_tokens=256,
    gpu_layers=0,
    local_files_only=True
)

print("ğŸ¤– Model Ä‘Ã£ load xong!\n")

# ===== TEST PROMPT =====
prompt = "Giáº£i thÃ­ch ngáº¯n gá»n LLaMA lÃ  gÃ¬ báº±ng tiáº¿ng Viá»‡t."

print("ğŸ“¨ Prompt:")
print(prompt)
print("\nğŸ§  AI Ä‘ang tráº£ lá»i...\n")

response = llm(prompt)

print("âœ… CÃ‚U TRáº¢ Lá»œI:\n")
print(response)
